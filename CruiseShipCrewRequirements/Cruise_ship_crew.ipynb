{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b132ac",
   "metadata": {},
   "source": [
    "# Cruise ship crew requrement estimation\n",
    "## Data overview\n",
    "In this notebook we are going to prepare dataset with records shown below and using logistic regression with spark to predict necesary crew for given ship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce84b41",
   "metadata": {},
   "source": [
    "Data:\n",
    "\n",
    "`Description: Measurements of ship size, capacity, crew, and age for 158 cruise ships.\n",
    "Variables/Columns\n",
    "Ship Name     1-20\n",
    "Cruise Line   21-40\n",
    "Age (as of 2013)   46-48\n",
    "Tonnage (1000s of tons)   50-56\n",
    "passengers (100s)   58-64\n",
    "Length (100s of feet)  66-72\n",
    "Cabins  (100s)   74-80\n",
    "Passenger Density   82-88\n",
    "Crew  (100s)   90-96`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a750189",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64437ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/08 11:03:00 WARN Utils: Your hostname, wojciech-VirtualBox resolves to a loopback address: 127.0.1.1; using 192.168.8.181 instead (on interface enp0s3)\n",
      "22/04/08 11:03:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/wojciech/.local/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/08 11:03:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('cruise').getOrCreate()\n",
    "df = spark.read.csv('cruise_ship_info.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be09b004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d854c6",
   "metadata": {},
   "source": [
    "Most of our data is in numerical form. Only Ship_name and Cruise_line are strings. Ship_name is useless we will drop it later on, but Cruse_line is usefull for us so we have to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4f3b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e2bd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"Cruise_line\", outputCol=\"cruise_cat\")\n",
    "indexed = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fc31c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c895bdd5",
   "metadata": {},
   "source": [
    "Using StringIndexer we transformed name of curuise line name into numerical value representing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed0119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5c40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "  inputCols=['Age',\n",
    "             'Tonnage',\n",
    "             'passengers',\n",
    "             'length',\n",
    "             'cabins',\n",
    "             'passenger_density',\n",
    "             'cruise_cat'],\n",
    "    outputCol=\"features\")\n",
    "output = assembler.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b791b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|crew|\n",
      "+--------------------+----+\n",
      "|[6.0,30.276999999...|3.55|\n",
      "|[6.0,30.276999999...|3.55|\n",
      "|[26.0,47.262,14.8...| 6.7|\n",
      "|[11.0,110.0,29.74...|19.1|\n",
      "|[17.0,101.353,26....|10.0|\n",
      "|[22.0,70.367,20.5...| 9.2|\n",
      "|[15.0,70.367,20.5...| 9.2|\n",
      "|[23.0,70.367,20.5...| 9.2|\n",
      "|[19.0,70.367,20.5...| 9.2|\n",
      "|[6.0,110.23899999...|11.5|\n",
      "|[10.0,110.0,29.74...|11.6|\n",
      "|[28.0,46.052,14.5...| 6.6|\n",
      "|[18.0,70.367,20.5...| 9.2|\n",
      "|[17.0,70.367,20.5...| 9.2|\n",
      "|[11.0,86.0,21.24,...| 9.3|\n",
      "|[8.0,110.0,29.74,...|11.6|\n",
      "|[9.0,88.5,21.24,9...|10.3|\n",
      "|[15.0,70.367,20.5...| 9.2|\n",
      "|[12.0,88.5,21.24,...| 9.3|\n",
      "|[20.0,70.367,20.5...| 9.2|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(\"features\", \"crew\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfff57",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753ef5d",
   "metadata": {},
   "source": [
    "First we have to stlit our data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3374242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select(\"features\", \"crew\")\n",
    "train_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6badef9",
   "metadata": {},
   "source": [
    "Next we can prepare our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b59e0ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/08 11:03:21 WARN Instrumentation: [77228b17] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.015144009704948483,-7.873785666729284e-05,-0.12565033423234856,0.3977215207194875,0.9079226466251031,-0.0006587663603538364,0.07134553252829551] Intercept: -1.1853267253041428\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(labelCol='crew')\n",
    "lrModel = lr.fit(train_data)\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: {} Intercept: {}\".format(lrModel.coefficients,lrModel.intercept))\n",
    "test_results = lrModel.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6193c67a",
   "metadata": {},
   "source": [
    "Now we can evaluate if our model is any good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3021c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4750538054677656\n",
      "R2: 0.9669631416349129\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: {}\".format(test_results.meanSquaredError))\n",
    "print(\"R2: {}\".format(test_results.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44620a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6892414710881561\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: {}\".format(test_results.rootMeanSquaredError))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
